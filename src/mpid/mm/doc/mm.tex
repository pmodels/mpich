%
% This file contains a discussion of a possible Multi-method device
% implementation of ADI3  

\documentclass[dvipdfm,twoside,11pt]{article}
\usepackage[dvipdfm]{hyperref} % Upgraded url package
\usepackage{epsf}       % Graphics
\usepackage{mpiman}     % Generic manual info

%\begin{itemize}
%\item First item
%\item Second item
%\end{itemize}
%
%\begin{enumerate}
%\item First item
%\item Second item
%\end{enumerate}
%
%\begin{description}
%\item First item
%\item Second item
%\end{description}
%
%\begin{figure}[ht]
%\centerline{\epsfbox{ntfigs/sample.ps}}
%\caption{Sample caption}
%\label{fig:sample-label}
%\end{figure}
%
%\label{sec:sample}
%Section~\ref{sec:sample}
%\texttt{sample}
%\begin{verbatim}
%stuff
%\end{verbatim}
%\section{sample}
%\subsection{Sub one}
%\subsubsection{Sub sub two}

\begin{document}
%
% Title page
\title{The Multi-Method Design for an Implementation of ADI-3 for MPICH2}
\author{David Ashton}
\maketitle

% Add a table of contents
%\clearpage
\pagenumbering{roman}
\setcounter{page}{0}
\cleardoublepage
%\setcounter{page}{3}
\pagestyle{plain}
\begingroup
\parskip=0pt
\tableofcontents
\bigskip
\endgroup
\bigskip

\clearpage

\pagenumbering{arabic}
\setcounter{page}{1}

\addcontentsline{toc}{section}{Abstract}
\begin{abstract}
ADI-3 is a full featured, abstract device interface used in the MPICH
implementation of MPI to provide a portability layer that allows
access to many performance-oriented features of a wide range of
communication systems.  ADI-3 allows research into wide range of
implementation issues in MPI.  This article discusses the multi-method
implementation of the ADI-3.
\end{abstract}

\section{Introduction}

\section{mm functions}
This section describes the multi-method functions.
\begin{verbatim}
/* connect/accept */
           int mm_open_port(MPID_Info *, char *);
           int mm_close_port(char *);
           int mm_accept(MPID_Info *, char *);
           int mm_connect(MPID_Info *, char *);
           int mm_send(int, char *, int);
           int mm_recv(int, char *, int);
           int mm_close(int);

/* requests */
MPID_Request * mm_request_alloc(void);
          void mm_request_free(MPID_Request *request_ptr);

/* communication agent/action requests */
          void mm_car_init(void);
          void mm_car_finalize(void);
      MM_Car * mm_car_alloc(void);
          void mm_car_free(MM_Car *car_ptr);

/* virtual connections */
          void mm_vc_init(void);
          void mm_vc_finalize(void);
    MPIDI_VC * mm_vc_from_communicator(MPID_Comm *comm_ptr, int rank);
    MPIDI_VC * mm_vc_from_context(int comm_context, int rank);
    MPIDI_VC * mm_vc_alloc(MM_METHOD method);
    MPIDI_VC * mm_vc_connect_alloc(MPID_Comm *comm_ptr, int rank);
           int mm_vc_free(MPIDI_VC *ptr);

/* buffer */
           int mm_choose_buffer(MPID_Request *request_ptr);
           int mm_reset_cars(MPID_Request *request_ptr);
           int mm_get_buffers_tmp(MPID_Request *request_ptr);
           int mm_release_buffers_tmp(MPID_Request *request_ptr);
           int mm_get_buffers_vec(MPID_Request *request_ptr);
           int vec_buffer_init(MPID_Request *request_ptr);
           int tmp_buffer_init(MPID_Request *request_ptr);
           int simple_buffer_init(MPID_Request *request_ptr);

/* progress */
           int mm_make_progress();

/* queues */
           int mm_post_recv(MM_Car *car_ptr);
           int mm_post_send(MM_Car *car_ptr);
           int mm_cq_test(void);
           int mm_cq_wait(void);
           int mm_cq_enqueue(MM_Car *car_ptr);
           int mm_create_post_unex(MM_Car *unex_head_car_ptr);
           int mm_enqueue_request_to_send(MM_Car *unex_head_car_ptr);
           int mm_post_rndv_clear_to_send(MM_Car *posted_car_ptr, MM_Car *rndv_rts_car_ptr);
           int mm_post_rndv_data_send(MM_Car *rndv_cts_car_ptr);

/* requests */
          void mm_inc_cc(MPID_Request *request_ptr);
          void mm_dec_cc(MPID_Request *request_ptr);
          void mm_dec_atomic(int *pcounter);
          void mm_inc_atomic(int *pcounter);
\end{verbatim}

\section{xfer}
This section describes the xfer functions.
\begin{verbatim}
int xfer_init               (int tag, MPID_Comm *comm_ptr, MPID_Request **request_pptr);
int xfer_recv_op            (MPID_Request *request_ptr, void *buf, int count, MPI_Datatype dtype, int first, int last, int src);
int xfer_recv_mop_op        (MPID_Request *request_ptr, void *buf, int count, MPI_Datatype dtype, int first, int last, int src);
int xfer_recv_forward_op    (MPID_Request *request_ptr, void *buf, int count, MPI_Datatype dtype, int first, int last, int src, int dest);
int xfer_recv_mop_forward_op(MPID_Request *request_ptr, void *buf, int count, MPI_Datatype dtype, int first, int last, int src, int dest);
int xfer_forward_op         (MPID_Request *request_ptr, int size, int src, int dest);
int xfer_send_op            (MPID_Request *request_ptr, const void *buf, int count, MPI_Datatype dtype, int first, int last, int dest);
int xfer_replicate_op       (MPID_Request *request_ptr, int dest);
int xfer_start              (MPID_Request *request_ptr);
\end{verbatim}

What is an xfer block? - A block is defined by an init call, followed by one 
or more xfer operations, and finally a start call.
Priority in a block is defined by the order of operations issued in a block.
Lower priority operations may make progress as long as they can be preempted
by higher priority operations.

Progress on blocks may occur in parallel.  Blocks are independent.

dependencies:
1) completion
2) progress
3) resource (buffer)

Xfer blocks are used to create graphs of cars. Multiple cars within an xfer 
block may be aggregated in the order issued.

mop = MPI operation
Do not add xfer\_mop\_send\_op because it is not necessary at the xfer level.

The xfer...mop functions generate cars like this:
(recv\_mop) - (send)
(recv) - (mop\_send)

The mop\_send exists at the car level, not the xfer level.

xfer\_recv\_forward\_op generates these cars:
(recv) - (send)

recv\_mop can be used for accumulate

send\_mop could cause remote operations to occur.  We will not use send\_mop 
currently.

\section{TCP}
This section deals with the design of the TCP method.

\subsection{MPI\_Send}
This is what happens when MPI\_Send is called.
\begin{verbatim}
MPI_Send
MPID_Send
MPID_Isend
xfer_init
xfer_send_op
xfer_start
mm_choose_buffer
mm_reset_cars
packer_post_read
mm_post_send
vc_ptr-> socket_post_write
socket_car_enqueue
\end{verbatim}

\subsection{MPID\_Progress\_wait - MPI\_Send}
This is what happens when the progress engine completes the send operation.
\begin{verbatim}
MPID_Progress_wait
mm_cq_test
mm_make_progress
socket_make_progress
sock_wait
socket_handle_written
socket_handle_written_vec
socket_car_dequeue_write
mm_cq_enqueue
\end{verbatim}

\subsection{Completion queue - MPI\_Send}
This is what the completion queue does when the send completes.
\begin{verbatim}
cq_handle_write_car
mm_dec_cc
mm_car_free
\end{verbatim}

\subsection{MPI\_Recv}
This is what happens when MPI\_Recv is called.
\begin{verbatim}
MPI_Recv
MPID_Recv
MPID_Irecv
xfer_init
xfer_recv_op
xfer_start
mm_choose_buffer
mm_reset_cars
mm_post_recv
1) matches unexpected message
   vc_ptr-> socket_merge_with_unexpected
   vc_ptr-> socket_merge_unexpected_data
2) does not match unexpected message
   enqueue into posted
unpacker_vc_ptr->post_write
\end{verbatim}

\subsection{MPID\_Progress\_wait - MPI\_Recv}
This is what happens when the progress engine completes the recv operation.
\begin{verbatim}
MPID_Progress_wait
mm_cq_test
mm_make_progress
socket_make_progress
sock_wait
socket_handle_read
1) head car
   mm_cq_enqueue(HEAD_CAR)
2) data car
   socket_read_data
   socket_read_vec
   socket_car_dequeue
   mm_cq_enqueue(DATA_CAR)
\end{verbatim}

\subsection{Completion queue - MPI\_Recv}
This is what the completion queue does when the recv completes
\begin{verbatim}
cq_handle_read_car
1) head car
   cq_handle_read_head_car
   1) matches posted
      vc_ptr-> socket_merge_with_posted
   2) unmatched
      mm_create_post_unex
      enqueue in unex
      vc_ptr->enqueue_read_at_head
2) data car
   cq_handle_read_data_car
   1) more data cars
      vc_ptr->enqueue_read_at_head
   2) last data car
      vc_ptr->post_read_pkt
\end{verbatim}

\section{Shared Memory}
This section covers the shared memory method.

\section{VIA}
This section covers the VIA method.

\section{VIA RDMA}
This section covers the VIA method that uses RDMA.

\section{Infiniband}
This section covers the Infiniband method.

\end{document}
